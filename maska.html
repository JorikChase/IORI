<html>
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.162.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.162.0/examples/jsm/"
            }
        }
    </script>

    <script type="module">
        import * as THREE from "three";
        import { OrbitControls } from "three/addons/controls/OrbitControls.js";
        import { RoomEnvironment } from "three/addons/environments/RoomEnvironment.js";
        import { GLTFLoader } from "three/addons/loaders/GLTFLoader.js";
        import { KTX2Loader } from "three/addons/loaders/KTX2Loader.js";
        import { MeshoptDecoder } from "three/addons/libs/meshopt_decoder.module.js";
        import { GUI } from "https://cdn.jsdelivr.net/npm/lil-gui@0.18.2/dist/lil-gui.esm.min.js";
        import { PlaneGeometry } from "three";

        // Mediapipe
        import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

        const { FaceLandmarker, FilesetResolver } = vision;

        const blendshapesMap = {
            // '_neutral': '',
            browDownLeft: "browDown_L",
            browDownRight: "browDown_R",
            browInnerUp: "browInnerUp",
            browOuterUpLeft: "browOuterUp_L",
            browOuterUpRight: "browOuterUp_R",
            cheekPuff: "cheekPuff",
            cheekSquintLeft: "cheekSquint_L",
            cheekSquintRight: "cheekSquint_R",
            eyeBlinkLeft: "eyeBlink_L",
            eyeBlinkRight: "eyeBlink_R",
            eyeLookDownLeft: "eyeLookDown_L",
            eyeLookDownRight: "eyeLookDown_R",
            eyeLookInLeft: "eyeLookIn_L",
            eyeLookInRight: "eyeLookIn_R",
            eyeLookOutLeft: "eyeLookOut_L",
            eyeLookOutRight: "eyeLookOut_R",
            eyeLookUpLeft: "eyeLookUp_L",
            eyeLookUpRight: "eyeLookUp_R",
            eyeSquintLeft: "eyeSquint_L",
            eyeSquintRight: "eyeSquint_R",
            eyeWideLeft: "eyeWide_L",
            eyeWideRight: "eyeWide_R",
            jawForward: "jawForward",
            jawLeft: "jawLeft",
            jawOpen: "jawOpen",
            jawRight: "jawRight",
            mouthClose: "mouthClose",
            mouthDimpleLeft: "mouthDimple_L",
            mouthDimpleRight: "mouthDimple_R",
            mouthFrownLeft: "mouthFrown_L",
            mouthFrownRight: "mouthFrown_R",
            mouthFunnel: "mouthFunnel",
            mouthLeft: "mouthLeft",
            mouthLowerDownLeft: "mouthLowerDown_L",
            mouthLowerDownRight: "mouthLowerDown_R",
            mouthPressLeft: "mouthPress_L",
            mouthPressRight: "mouthPress_R",
            mouthPucker: "mouthPucker",
            mouthRight: "mouthRight",
            mouthRollLower: "mouthRollLower",
            mouthRollUpper: "mouthRollUpper",
            mouthShrugLower: "mouthShrugLower",
            mouthShrugUpper: "mouthShrugUpper",
            mouthSmileLeft: "mouthSmile_L",
            mouthSmileRight: "mouthSmile_R",
            mouthStretchLeft: "mouthStretch_L",
            mouthStretchRight: "mouthStretch_R",
            mouthUpperUpLeft: "mouthUpperUp_L",
            mouthUpperUpRight: "mouthUpperUp_R",
            noseSneerLeft: "noseSneer_L",
            noseSneerRight: "noseSneer_R",
            // '': 'tongueOut'
        };

        //

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.toneMapping = THREE.ACESFilmicToneMapping;
        document.body.appendChild(renderer.domElement);

        const camera = new THREE.PerspectiveCamera(
            60,
            window.innerWidth / window.innerHeight,
            1,
            100,
        );
        camera.position.z = 5;

        const scene = new THREE.Scene();
        scene.scale.x = -1;

        const environment = new RoomEnvironment();
        const pmremGenerator = new THREE.PMREMGenerator(renderer);

        scene.background = new THREE.Color(0x0f0f0f);
        scene.environment = pmremGenerator.fromScene(environment).texture;

        const controls = new OrbitControls(camera, renderer.domElement);

        // Face

        let face, eyeL, eyeR;
        const eyeRotationLimit = THREE.MathUtils.degToRad(30);

        const ktx2Loader = new KTX2Loader()
            .setTranscoderPath("jsm/libs/basis/")
            .detectSupport(renderer);

        const videoElement = document.createElement("video");
        videoElement.src =
            "https://cdn.glitch.me/e4631427-87ee-420d-ba2f-6ac222aa598b/autoportrait.mp4?v=1736802925069"; // Update the path to your actual video file
        videoElement.loop = true;
        videoElement.muted = true;
        videoElement.play();

        const videoTexture = new THREE.VideoTexture(videoElement);
        videoTexture.colorSpace = THREE.SRGBColorSpace;

        new GLTFLoader()
            .setKTX2Loader(ktx2Loader)
            .setMeshoptDecoder(MeshoptDecoder)
            .load("/IORI/assets/facecap.glb", (gltf) => {
                const mesh = gltf.scene.children[0];
                scene.add(mesh);

                const head = mesh.getObjectByName("mesh_2");
                if (head) {
                    // Create a custom material that preserves morphs
                    const customMaterial = new THREE.MeshBasicMaterial({
                        map: videoTexture,
                        morphTargets: true, // Enable morph targets
                        side: THREE.DoubleSide,
                        shininess: 1,
                        bumpMap: videoTexture,
                        bump: 1,
                    });

                    // Set up video texture parameters
                    videoTexture.wrapS = THREE.ClampToEdgeWrapping;
                    videoTexture.wrapT = THREE.ClampToEdgeWrapping;
                    videoTexture.minFilter = THREE.LinearFilter;
                    videoTexture.magFilter = THREE.LinearFilter;

                    // Create texture matrix for controlling UV transformation
                    const textureMatrix = new THREE.Matrix3();
                    const updateTextureMatrix = (offset, scale) => {
                        textureMatrix.setUvTransform(
                            offset.x,
                            offset.y,
                            scale.x,
                            scale.y,
                            0, // rotation
                            0.5,
                            0.5, // center point for scale/rotation
                        );
                    };

                    // Apply the material to the head
                    head.material = customMaterial;

                    // Create GUI controls for texture adjustment
                    const textureControls = {
                        offsetX: 0.215,
                        offsetY: 0.103,
                        scaleX: 0.000135, // Start with very small scale as in your original code
                        scaleY: 0.000145,
                        updateTexture: function () {
                            videoTexture.offset.set(this.offsetX, this.offsetY);
                            videoTexture.repeat.set(this.scaleX, this.scaleY);
                            videoTexture.needsUpdate = true;
                        },
                    };

                    const gui = new GUI();
                    const textureFolder = gui.addFolder("Texture Controls");
                    textureFolder
                        .add(textureControls, "offsetX", -1, 1, 0.001)
                        .onChange(() => textureControls.updateTexture());
                    textureFolder
                        .add(textureControls, "offsetY", -1, 1, 0.001)
                        .onChange(() => textureControls.updateTexture());
                    textureFolder
                        .add(textureControls, "scaleX", 0.0001, 0.001, 0.0001)
                        .onChange(() => textureControls.updateTexture());
                    textureFolder
                        .add(textureControls, "scaleY", 0.0001, 0.001, 0.0001)
                        .onChange(() => textureControls.updateTexture());
                    textureFolder.open();

                    // Initial texture update
                    textureControls.updateTexture();

                    // Set up morph targets
                    if (
                        head.morphTargetDictionary &&
                        head.morphTargetInfluences
                    ) {
                        const morphFolder = gui.addFolder("Morphs");
                        for (const [key, value] of Object.entries(
                            head.morphTargetDictionary,
                        )) {
                            morphFolder
                                .add(
                                    head.morphTargetInfluences,
                                    value,
                                    0,
                                    1,
                                    0.01,
                                )
                                .name(key.replace("blendShape1.", ""))
                                .listen();
                        }
                        morphFolder.open();
                    }
                }

                face = mesh.getObjectByName("mesh_2");
                eyeL = mesh.getObjectByName("eyeLeft");
                eyeR = mesh.getObjectByName("eyeRight");
                const customMaterial = new THREE.MeshBasicMaterial({
                    map: videoTexture,
                    morphTargets: true, // Enable morph targets
                    side: THREE.DoubleSide,
                });
                eyeL.material = customMaterial;
                eyeR.material = customMaterial;
                renderer.setAnimationLoop(animate);
            });

        // Video Texture

        const video = document.createElement("video");

        const texture = new THREE.VideoTexture(video);
        texture.colorSpace = THREE.SRGBColorSpace;

        const geometry = new THREE.PlaneGeometry(1, 1);
        const material = new THREE.MeshBasicMaterial({
            map: texture,
            depthWrite: false,
        });
        const videomesh = new THREE.Mesh(geometry, material);
        //scene.add( videomesh );

        // MediaPipe

        const filesetResolver = await FilesetResolver.forVisionTasks(
            "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm",
        );

        const faceLandmarker = await FaceLandmarker.createFromOptions(
            filesetResolver,
            {
                baseOptions: {
                    modelAssetPath:
                        "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
                    delegate: "GPU",
                },
                outputFaceBlendshapes: true,
                outputFacialTransformationMatrixes: true,
                runningMode: "VIDEO",
                numFaces: 1,
            },
        );

        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            navigator.mediaDevices
                .getUserMedia({ video: { facingMode: "user" } })
                .then(function (stream) {
                    video.srcObject = stream;
                    video.play();
                })
                .catch(function (error) {
                    console.error("Unable to access the camera/webcam.", error);
                });
        }

        const transform = new THREE.Object3D();

        function animate() {
            if (video.readyState >= HTMLMediaElement.HAVE_METADATA) {
                const results = faceLandmarker.detectForVideo(
                    video,
                    Date.now(),
                );

                if (results.facialTransformationMatrixes.length > 0) {
                    const facialTransformationMatrixes =
                        results.facialTransformationMatrixes[0].data;

                    transform.matrix.fromArray(facialTransformationMatrixes);
                    transform.matrix.decompose(
                        transform.position,
                        transform.quaternion,
                        transform.scale,
                    );

                    const object = scene.getObjectByName("grp_transform");

                    //object.position.x = transform.position.x;
                    //object.position.y = transform.position.z + 40;
                    //object.position.z = - transform.position.y;

                    object.rotation.x = transform.rotation.x;
                    object.rotation.y = transform.rotation.z;
                    object.rotation.z = -transform.rotation.y;
                    console.log(object.rotation.x);
                    function handleRotationRange(rotation) {
                        // Calculate the size of each segment
                        const range = 0.5 - -0.45; // Total range: 0.95
                        const segmentSize = range / 8; // Size of each segment: 0.11875

                        // Normalize the rotation value to be within our range
                        const normalizedRotation = Math.max(
                            -0.45,
                            Math.min(0.5, rotation),
                        );

                        // Calculate which segment the rotation falls into
                        switch (true) {
                            case normalizedRotation < -0.45 + segmentSize: // -0.45 to -0.33125
                                console.log(
                                    "Case 1: Extreme negative rotation",
                                );
                                break;

                            case normalizedRotation < -0.45 + segmentSize * 2: // -0.33125 to -0.2125
                                console.log("Case 2: High negative rotation");
                                break;

                            case normalizedRotation < -0.45 + segmentSize * 3: // -0.2125 to -0.09375
                                console.log("Case 3: Medium negative rotation");
                                break;

                            case normalizedRotation < -0.45 + segmentSize * 4: // -0.09375 to 0.025
                                console.log("Case 4: Low negative rotation");
                                break;

                            case normalizedRotation < -0.45 + segmentSize * 5: // 0.025 to 0.14375
                                console.log("Case 5: Low positive rotation");
                                break;

                            case normalizedRotation < -0.45 + segmentSize * 6: // 0.14375 to 0.2625
                                console.log("Case 6: Medium positive rotation");
                                break;

                            case normalizedRotation < -0.45 + segmentSize * 7: // 0.2625 to 0.38125
                                console.log("Case 7: High positive rotation");
                                break;

                            default: // 0.38125 to 0.5
                                console.log(
                                    "Case 8: Extreme positive rotation",
                                );
                        }
                    }
                    handleRotationRange(object.rotation.x);
                }

                if (results.faceBlendshapes.length > 0) {
                    const faceBlendshapes =
                        results.faceBlendshapes[0].categories;

                    // Morph values does not exist on the eye meshes, so we map the eyes blendshape score into rotation values
                    const eyeScore = {
                        leftHorizontal: 0,
                        rightHorizontal: 0,
                        leftVertical: 0,
                        rightVertical: 0,
                    };

                    for (const blendshape of faceBlendshapes) {
                        const categoryName = blendshape.categoryName;
                        const score = blendshape.score;

                        const index =
                            face.morphTargetDictionary[
                                blendshapesMap[categoryName]
                            ];

                        if (index !== undefined) {
                            face.morphTargetInfluences[index] = score;
                        }

                        // There are two blendshape for movement on each axis (up/down , in/out)
                        // Add one and subtract the other to get the final score in -1 to 1 range
                        switch (categoryName) {
                            case "eyeLookInLeft":
                                eyeScore.leftHorizontal += score;
                                break;
                            case "eyeLookOutLeft":
                                eyeScore.leftHorizontal -= score;
                                break;
                            case "eyeLookInRight":
                                eyeScore.rightHorizontal -= score;
                                break;
                            case "eyeLookOutRight":
                                eyeScore.rightHorizontal += score;
                                break;
                            case "eyeLookUpLeft":
                                eyeScore.leftVertical -= score;
                                break;
                            case "eyeLookDownLeft":
                                eyeScore.leftVertical += score;
                                break;
                            case "eyeLookUpRight":
                                eyeScore.rightVertical -= score;
                                break;
                            case "eyeLookDownRight":
                                eyeScore.rightVertical += score;
                                break;
                        }
                    }

                    eyeL.rotation.z =
                        eyeScore.leftHorizontal * eyeRotationLimit;
                    eyeR.rotation.z =
                        eyeScore.rightHorizontal * eyeRotationLimit;
                    eyeL.rotation.x = eyeScore.leftVertical * eyeRotationLimit;
                    eyeR.rotation.x = eyeScore.rightVertical * eyeRotationLimit;
                }
            }

            videomesh.scale.x = video.videoWidth / 100;
            videomesh.scale.y = video.videoHeight / 100;

            if (videoTexture) {
                videoTexture.needsUpdate = true;
            }

            renderer.render(scene, camera);
            controls.update();
        }

        window.addEventListener("resize", function () {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</html>
